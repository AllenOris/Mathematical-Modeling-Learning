# 决策论

决策论是讨论，根据已有的信息，我们要如何进行决策？

> 考虑分类问题，实际上是在对输入空间进行划分。哪一种划分效果最好？

## 1. 最小化错分类概率

> prior probability(先验概率，是事件的概率) and posterior probability(后验概率[知道了一些事情后，事件的概率，由先验概率求得的反向条件概率]) 
> 
> decision regions, decision boundaries / decision surfaces; 一个决策域可以是很多块》

对于一个新的输入，选择具有最高后验概率的分类。

## 2. 最小化预期损失

每一种分类错误，可能的代价不同。使用loss matrix 定义各种分类情况的loss.优化loss function. 【utility function是效用函数，与loss function相反】

## 3. reject option

对于一个模型，在关于某一部分输入做预测时，效果可能不够好【即此时，对某个输入做出各种分类时，没有某个后验概率显著的大】，原因可能是输入的数据维度并不能很好的表现在这一区域的差异。对于这一部分输入考虑使用其他手段进行预测，不使用模型预测的结果。于是设置一个【概率】作为【对于这个输入，关于各种分类的所有后验概率最大的一个】的阈值。只有超过这个阈值，才接受模型的结果。

## 4. [推断与决策](https://blog.csdn.net/danieljianfeng/article/details/41896323)

> 做出分类，经过推断、决策两个阶段。但实际实现上有不同的形式。
> 
> 生成模型、判别模型、判别函数.

* 生成模型(generative models)：条件概率 + 先验概率 => 后验概率 => 决策理论判断正确分类【朴素贝叶斯】

生成模型的要求比较高，需要学习得到输入数据x和类别的联合分布。在实际的应用中，x的维度往往非常的高，只有在非常大的训练数据下我们才能得到比较合理的类条件分布（class-conditional distribution）。庆幸地是，先验概率 比较容易计算，只需计算训练样本中每一类数据占整个训练数据的百分比。虽然生成模型的计算比较复杂，需要学习每一个类的分布，但就可以反映同一类数据本身的一些特点。

* 判别模型(discriminative function)：判别模型直接学习后验概率，然后利用决策理论判断输入数据属于哪一类。【逻辑回归、感知机】

如果仅仅是处理分类问题，已知 ，就可以很好的解决这个问题，生成模型需要计算类条件概率和先验概率，这就增加的计算量。相反，判别模型就是直接去求解 ，学习不同类别之间的最优分类面，反映不同类数据之间的差异。但这类模型不能反映数据本身的特点，只能告诉你该数据属于哪个类，而不能反映整个场景的情况。

* 判别函数(discriminant function)：不涉及概率，直接从训练数据学习得到输入到类别的映射。推断与决策被共同执行。

最简单的判别函数只是学到从输入空间到类别空间的一个映射，不涉及任何的概率，因此该方法不能量化该数据属于某个类的可能性。此外，该方法把推理阶段和决策阶段的任务合在一起进行，但在实际过程中我们需要更加不同的应用选择不同的决策方法。

> [Andrew Ng 的论文](https://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf)对此作了较为全面的分析，生成模型（朴素贝叶斯）在少量样本的情况下，可以取得更好的精确率，判别模型（logistics 回归）在样本增加的情况下，逐渐逼近前者的概率；

一般，获取后验概率是比较重要的事情。

1. Minimizing risk. 当loss matrix在不断改变时，先计算后验概率再借助loss matrix进行分类，仙姑低于判别函数，可以避免很多revision.

2. Reject option.

3. Compensating for class priors. 输入数据中，各类别的数据数量差别可能很大，需要借助后验概率进行弥补，构建balanced dataset，增加泛用性。【如何构建？控制各类别输入比例即可】

4. Combining models. 可能要和其他预测模型(heterogeneous informaintion)相结合。一般构建分别构建两个系统，效果很更好【预设两者是独立的】。于是需要中间结果计算联合分布概率。

## 5. 回归问题的决策

* loss function也是在衡量，让输入最大可能的取值【只不过取值变成连续的了，是一个分布函数，因而取最高点】。

* 最朴素的衡量是squared loss，但它对于【逆问题】中经常出现的 [multimodal distribution](https://en.wikipedia.org/wiki/Multimodal_distribution) 表现很差，需要更复杂的衡量方式。

> Minkowski loss 是一种更泛化的衡量方式
> 逆问题：是一个关于如何将观测和测量的结果转换为物体或系统的信息的广义框架。

***

> referencing: PRML, Bishop
> 20190709